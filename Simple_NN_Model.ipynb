{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5a37894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQuestions for Olivier-\\n\\n1. How was this data collected? Read off of patents by a person? Entered by those filing the patent?\\nWhere is the company information?\\nHow to make sense of the location id? (is that the company?)\\n\\n2. Is there some virtual database of patent applications in document form?\\nStuff like layout LM that they use for automated invoicing could auto get this info if there's some big database of stuff \\nin document form that otherwise people would have to go through?\\n\\n3. On a first pass, you see some data inconsistencies (non english alphabet letters, entry errors, etc)\\nWhat's the process on data cleaning this?\\n\\n4. I saw your cool paper on evaluation stuff. I didn't have time to dive in yet but that obviously is a wonderful standard for\\nevaluating everything. This isn't really a question just wanted to aknowledge that.\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Questions for Olivier-\n",
    "\n",
    "1. How was this data collected? Read off of patents by a person? Entered by those filing the patent?\n",
    "Where is the company information?\n",
    "How to make sense of the location id? (is that the company?)\n",
    "\n",
    "2. Is there some virtual database of patent applications in document form?\n",
    "Stuff like layout LM that they use for automated invoicing could auto get this info if there's some big database of stuff \n",
    "in document form that otherwise people would have to go through?\n",
    "\n",
    "3. On a first pass, you see some data inconsistencies (non english alphabet letters, entry errors, etc)\n",
    "What's the process on data cleaning this?\n",
    "\n",
    "4. I saw your cool paper on evaluation stuff. I didn't have time to dive in yet but that obviously is a wonderful standard for\n",
    "evaluating everything. This isn't really a question just wanted to aknowledge that.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e157ec8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>inventor_sequence</th>\n",
       "      <th>inventor_id</th>\n",
       "      <th>raw_inventor_name_first</th>\n",
       "      <th>raw_inventor_name_last</th>\n",
       "      <th>deceased_flag</th>\n",
       "      <th>rawlocation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222806</th>\n",
       "      <td>6495058</td>\n",
       "      <td>3</td>\n",
       "      <td>0eayxg6ntbpb7i43or67xz50b</td>\n",
       "      <td>Gabrielle Holly</td>\n",
       "      <td>(Spangler) Detzel</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>5mvvk75d3r1yecdwqkm47hbsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61259</th>\n",
       "      <td>10828027</td>\n",
       "      <td>0</td>\n",
       "      <td>fl:da_ln:(tarinelli)racenet-1</td>\n",
       "      <td>Danyel</td>\n",
       "      <td>(Tarinelli) Racenet</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>6bpux38ynbiuau8xgyykwjumi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35750</th>\n",
       "      <td>6920319</td>\n",
       "      <td>3</td>\n",
       "      <td>fl:ma_ln:agren-1</td>\n",
       "      <td>Mattias</td>\n",
       "      <td>?gren</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>tycghlb8ec7e39nv26yaj4k4n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316994</th>\n",
       "      <td>8688758</td>\n",
       "      <td>0</td>\n",
       "      <td>fl:pe_ln:ahgren-1</td>\n",
       "      <td>Per</td>\n",
       "      <td>?hgren</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>kab0alj30ub6sqq5essuf2lwn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362101</th>\n",
       "      <td>8372339</td>\n",
       "      <td>2</td>\n",
       "      <td>fl:ma_ln:ahlund-1</td>\n",
       "      <td>Mats-?ke</td>\n",
       "      <td>?hlund</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>4hp04uyj6gy2anenelldzqe6x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>8601984</td>\n",
       "      <td>1</td>\n",
       "      <td>fl:da_ln:vreb-1</td>\n",
       "      <td>Dag</td>\n",
       "      <td>Øvrebø</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>vw03ylcos0gzw2e8k7cvijkl4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478656</th>\n",
       "      <td>9990505</td>\n",
       "      <td>0</td>\n",
       "      <td>fl:er_ln:uner-1</td>\n",
       "      <td>Eric Ridvan</td>\n",
       "      <td>Üner</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>8di7ozemfh90jscsgoruxkr7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225302</th>\n",
       "      <td>6610666</td>\n",
       "      <td>0</td>\n",
       "      <td>0egryt9joungc4nyibksf2jrt</td>\n",
       "      <td>Jim</td>\n",
       "      <td>åkerblom</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>dp67qweekbbwzw1tp5tn9g5ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300292</th>\n",
       "      <td>6468680</td>\n",
       "      <td>1</td>\n",
       "      <td>fl:le_ln:akesson-1</td>\n",
       "      <td>Leif</td>\n",
       "      <td>åkesson</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>pazrzq9n71i6s2sws3qy17788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238186</th>\n",
       "      <td>D453154</td>\n",
       "      <td>0</td>\n",
       "      <td>fl:pe_ln:astradsson-1</td>\n",
       "      <td>Petter</td>\n",
       "      <td>åstradsson</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>455pjw0raxjp1rfr6yoixe1vc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patent_id inventor_sequence                    inventor_id  \\\n",
       "222806   6495058                 3      0eayxg6ntbpb7i43or67xz50b   \n",
       "61259   10828027                 0  fl:da_ln:(tarinelli)racenet-1   \n",
       "35750    6920319                 3               fl:ma_ln:agren-1   \n",
       "316994   8688758                 0              fl:pe_ln:ahgren-1   \n",
       "362101   8372339                 2              fl:ma_ln:ahlund-1   \n",
       "...          ...               ...                            ...   \n",
       "4162     8601984                 1                fl:da_ln:vreb-1   \n",
       "478656   9990505                 0                fl:er_ln:uner-1   \n",
       "225302   6610666                 0      0egryt9joungc4nyibksf2jrt   \n",
       "300292   6468680                 1             fl:le_ln:akesson-1   \n",
       "238186   D453154                 0          fl:pe_ln:astradsson-1   \n",
       "\n",
       "       raw_inventor_name_first raw_inventor_name_last deceased_flag  \\\n",
       "222806         Gabrielle Holly      (Spangler) Detzel         FALSE   \n",
       "61259                   Danyel    (Tarinelli) Racenet         FALSE   \n",
       "35750                  Mattias                  ?gren         FALSE   \n",
       "316994                     Per                 ?hgren         FALSE   \n",
       "362101                Mats-?ke                 ?hlund         FALSE   \n",
       "...                        ...                    ...           ...   \n",
       "4162                       Dag                 Øvrebø         FALSE   \n",
       "478656             Eric Ridvan                   Üner         FALSE   \n",
       "225302                     Jim               åkerblom         FALSE   \n",
       "300292                    Leif                åkesson         FALSE   \n",
       "238186                  Petter             åstradsson         FALSE   \n",
       "\n",
       "                   rawlocation_id  \n",
       "222806  5mvvk75d3r1yecdwqkm47hbsc  \n",
       "61259   6bpux38ynbiuau8xgyykwjumi  \n",
       "35750   tycghlb8ec7e39nv26yaj4k4n  \n",
       "316994  kab0alj30ub6sqq5essuf2lwn  \n",
       "362101  4hp04uyj6gy2anenelldzqe6x  \n",
       "...                           ...  \n",
       "4162    vw03ylcos0gzw2e8k7cvijkl4  \n",
       "478656  8di7ozemfh90jscsgoruxkr7b  \n",
       "225302  dp67qweekbbwzw1tp5tn9g5ig  \n",
       "300292  pazrzq9n71i6s2sws3qy17788  \n",
       "238186  455pjw0raxjp1rfr6yoixe1vc  \n",
       "\n",
       "[500000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First, get the data from the dissambioguation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "data_size = 500000\n",
    "\n",
    "#import data\n",
    "\n",
    "raw_inv = pd.read_csv(\"g_inventor_not_disambiguated.tsv\", sep=\"\\t\", dtype=str, nrows = data_size)\n",
    "raw_inv = raw_inv.sort_values(by=[\"raw_inventor_name_last\"])\n",
    "display(raw_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfd2a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Levenstein distance implementation- inspired from the internet\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "def lev_dist(a, b):\n",
    "    @lru_cache(None) \n",
    "    def min_dist(s1, s2):\n",
    "        if s1 == len(a) or s2 == len(b):\n",
    "            return len(a) - s1 + len(b) - s2\n",
    "        if a[s1] == b[s2]:\n",
    "            return min_dist(s1 + 1, s2 + 1)\n",
    "        return 1 + min(\n",
    "            min_dist(s1, s2 + 1),      \n",
    "            min_dist(s1 + 1, s2),      \n",
    "            min_dist(s1 + 1, s2 + 1),  \n",
    "        )\n",
    "\n",
    "    return min_dist(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddc90e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37046.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#compare inventors to row above, creates semi realistic scenario where last names will generally be the same\n",
    "#a scenario where some pre built filter has generally eliminated matches that do not have the same last name\n",
    "'''\n",
    "This should be vectorized, iterating through dfs is bad practice\n",
    "\n",
    "'''\n",
    "comp_arr = np.zeros((len(raw_inv.index), 4))\n",
    "y_arr = np.zeros((len(raw_inv.index), 1))\n",
    "ind = -1\n",
    "for index, row in raw_inv.iterrows():\n",
    "    curr = row\n",
    "    if ind==-1:\n",
    "        hold = curr\n",
    "        ind = ind + 1\n",
    "        continue\n",
    "    if (type(curr['raw_inventor_name_first']) == str) and (type(hold['raw_inventor_name_first']) == str):\n",
    "        comp_arr[ind,0] = lev_dist(curr['raw_inventor_name_first'].lower(), hold['raw_inventor_name_first'].lower()) #firstname diff\n",
    "    if (type(curr['raw_inventor_name_last']) == str) and (type(hold['raw_inventor_name_last']) == str):\n",
    "        comp_arr[ind,1]= lev_dist(curr['raw_inventor_name_last'].lower(), hold['raw_inventor_name_last'].lower()) #last name diff\n",
    "    if (type(curr['deceased_flag']) == str) and (type(hold['deceased_flag']) == str):\n",
    "        comp_arr[ind,2] = (curr['deceased_flag'].lower() == hold['deceased_flag'].lower()) #is living status same?\n",
    "    if (type(curr['rawlocation_id']) == str) and (type(hold['rawlocation_id']) == str):\n",
    "        comp_arr[ind,3] = (curr['rawlocation_id'].lower() == hold['rawlocation_id'].lower()) #is location same?\n",
    "    if (type(curr['inventor_id']) == str) and (type(hold['inventor_id']) == str):\n",
    "        y_arr[ind,0] = (curr['inventor_id'].lower() == hold['inventor_id'].lower()) #is inventor same?\n",
    "    ind = ind + 1\n",
    "    hold = curr\n",
    "num_matches = np.sum(y_arr)\n",
    "print(num_matches)\n",
    "#in this example, it's ~37k matches, so it's something like 8% of the dataset is matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcb1e242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split into test and train, convert to torch, and set up batches\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = comp_arr\n",
    "y = y_arr\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len   \n",
    "batch_size = 64\n",
    "train_data = Data(X_train, y_train)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = Data(X_test, y_test)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "365ea38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the model class ie. the feedforward layer\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "input_dim = 4\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        nn.init.kaiming_uniform_(self.layer_1.weight, nonlinearity=\"relu\")\n",
    "        self.layer_2 = nn.Linear(hidden_dim, output_dim)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.layer_1(x))\n",
    "        x = torch.nn.functional.sigmoid(self.layer_2(x))\n",
    "        return x\n",
    "       \n",
    "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "learning_rate = 0.1\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "144bbb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "num_epochs = 25\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss_values.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "#crazy that running locally the training takes not even 2 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e86c4d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''I do a simple accuracy calculation here but obviously the next step is to use the library that was in that paper\n",
    "because this is a terrible way of evaluating, specifically for entity resolution'''\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        outputs = model(X)\n",
    "        predicted = np.where(outputs < 0.5, 0, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y.numpy()).sum().item()\n",
    "\n",
    "print(f'Accuracy {100 * correct // total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa520e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
